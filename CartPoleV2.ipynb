{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param\n",
    "l = 0.98 # lambda\n",
    "a = 0.1 # learning rate\n",
    "eg = 1.0 # epsilon greedy\n",
    "egMin = 0.05\n",
    "maxBufferSize = 500000\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(Agent, self).__init__(name='mon_agent')\n",
    "    # Define your layers here.\n",
    "    #self.dense1 = tf.keras.layers.Dense(16, activation='relu', input_shape=(4,))\n",
    "    self.dense1 = tf.keras.layers.Dense(8, activation='relu')\n",
    "    #self.dense2 = tf.keras.layers.Dense(8, activation='relu')\n",
    "    self.dense3 = tf.keras.layers.Dense(2, activation='relu')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    tmp = self.dense1(inputs)\n",
    "    #tmp = self.dense2(tmp)\n",
    "    return self.dense3(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coach(tf.keras.Model):\n",
    "    def __init__(self, agent):\n",
    "        super(Coach, self).__init__()\n",
    "        self.agent = agent\n",
    "\n",
    "    def call(self, inputs):\n",
    "        [states, masks] = inputs\n",
    "        #tf.print(\"states : \", states)\n",
    "        #tf.print(\"masks : \", masks)\n",
    "        return agent(states) * masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHistory(history) :\n",
    "    #print(history.history.keys())\n",
    "    plt.figure(figsize=(15.0,10.0))\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2) \n",
    "    fig.set_size_inches(15.0, 7.0)         \n",
    "    axes[0].plot(history.history['loss'], label=\"loss\")\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(history.history['accuracy'], label=\"accuracy\")\n",
    "    axes[1].legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "agent.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "agent.build(tf.TensorShape([None,4]))\n",
    "#agent.build(tf.TensorShape([None,2]))\n",
    "\n",
    "coach = Coach(agent)\n",
    "coach.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"mse\",\n",
    "    metrics=['accuracy'])\n",
    "coach([tf.keras.Input(shape=(4,)), tf.keras.Input(shape=(2,))])\n",
    "#coach([tf.keras.Input(shape=(2,)), tf.keras.Input(shape=(2,))])\n",
    "\n",
    "\n",
    "agent.summary()\n",
    "coach.summary()\n",
    "\n",
    "#print(agent([[0,0,0,0]]));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "memory = [] #{ \"states\":[], \"masks\":[], \"actions\":[], \"values\":[]}\n",
    "loss = []\n",
    "accuracy = []\n",
    "for epi in range(1,100) :\n",
    "    #memory = { \"states\":[], \"masks\":[], \"actions\":[], \"values\":[]}\n",
    "    state = env.reset() #[2:]\n",
    "    c0 = 0\n",
    "    c1 = 0\n",
    "    # * * * explore * * *\n",
    "    print(epi)\n",
    "    for step in range(1000): #epi * 100):\n",
    "        env.render()\n",
    "        #print(state)\n",
    "        if (random.random() > eg) :\n",
    "            c0 +=1\n",
    "            Qs = agent([state])[0];\n",
    "            action = np.argmax(Qs);\n",
    "            Q = Qs[action]\n",
    "            #print(\"State: \", state, \" Qs: \", Qs.numpy(), \" Action: \", action, \" Q: \", Q.numpy())\n",
    "        else :\n",
    "            c1 +=1\n",
    "            Qs = agent([state])[0];\n",
    "            action = random.randrange(2)\n",
    "            Q = Qs[action]\n",
    "            #print(\"State: \", state, \" Action: \", action, \" Q: \", Q.numpy())\n",
    "\n",
    "        mask = np.zeros(2)\n",
    "        mask[action] = 1\n",
    "        mem = { \"s\": state, \"a\": action, \"m\": mask}\n",
    "        state, rewards, done, info = env.step(action)\n",
    "        #state = state[2:]\n",
    "        if done : rewards = 0.0\n",
    "        mem[\"r\"] = rewards\n",
    "        mem[\"sp\"] = state\n",
    "        mem[\"d\"] = done\n",
    "        memory.append(mem)\n",
    "        #input()\n",
    "        print(mem)\n",
    "        #Q0 = Q    \n",
    "        #if not done : \n",
    "        #    #rewards -= 1.0\n",
    "        #    Qs = agent([state])[0];\n",
    "        #    #Q = Q + a * (rewards + l * np.max(Qs) - Q)\n",
    "        #    Q = rewards + l * np.max(Qs)\n",
    "        #    #Q = Q.numpy()\n",
    "        #else :\n",
    "        #    #rewards = -1.0\n",
    "        #    rewards = 0.0\n",
    "        #    #print(Q.numpy(), ' => ')\n",
    "        #    Q = Q + a * (rewards - Q)\n",
    "        #    #Q = 0.0\n",
    "        #    print('.', end='')\n",
    "        #    #if o0 == None : o0 = Q #.numpy()\n",
    "\n",
    "        \n",
    "        #print(rewards, done, \" Q : \", Q0.numpy(), \" => \", Q.numpy())\n",
    "        #print(\"rewards: \", rewards, \" Qs: \", Qs.numpy(), \" Q: \", Q.numpy(), \" mask: \", mask)\n",
    "        \n",
    "        #memory[\"values\"].append(mask * Q) #.numpy())\n",
    "        #memory[\"targets\"].append( { \"mask\": mask, \"action\":action, \"value\":Q.numpy() } )\n",
    "        if done : print('.', end=''); state = env.reset() #[2:]\n",
    "        #if rewards == 0 : state = env.reset()\n",
    "    \n",
    "    \n",
    "    #print(memory)\n",
    "    #eg = max(egMin, eg*.9)\n",
    "    #print(\"\\r\\neG: \", eg, \"; \", c0,\"-\",c1,\"/\",c0+c1)\n",
    "    \n",
    "        if len(memory)>500 :\n",
    "            while len(memory) > maxBufferSize :\n",
    "                memory = random.sample(memory, maxBufferSize)\n",
    "                #index = random.randrange(maxBufferSize)\n",
    "                #del memory[\"states\"][index]\n",
    "                #del memory[\"masks\"][index]\n",
    "                #del memory[\"actions\"][index]\n",
    "                #del memory[\"values\"][index]\n",
    "\n",
    "            # * * * learn * * *\n",
    "\n",
    "            batch = random.sample(memory, batchSize)\n",
    "            bs = [ b[\"s\"] for b in batch ]\n",
    "            bm = [ b[\"m\"] for b in batch ]\n",
    "            by = [ b[\"m\"] * ( b['r'] if b['d'] else b['r'] + a * np.max(agent([b['sp']])[0]) )\n",
    "                   for b in batch ]\n",
    "\n",
    "            history = coach.fit(\n",
    "                [np.array(bs), np.array(bm)],\n",
    "                np.array(by),\n",
    "                verbose=0)\n",
    "            loss.append(history.history['loss'])\n",
    "            accuracy.append(history.history['accuracy'])\n",
    "            #print(history.history['loss'])\n",
    "    \n",
    "    #plt.figure(figsize=(15.0,7.0))\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2) \n",
    "    fig.set_size_inches(15.0, 7.0)         \n",
    "    axes[0].plot(loss, label=\"loss\")\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(accuracy, label=\"accuracy\")\n",
    "    axes[1].legend()\n",
    "    plt.show()\n",
    "    loss = []\n",
    "    accuracy = []\n",
    "\n",
    "    #showHistory(history)\n",
    "    \n",
    "    #print(agent([s0])[0].numpy(), \" <= \", o0)\n",
    "    #break\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()\n",
    "#agent.save_weights('CartPoleV1.tf')\n",
    "#agent.load_weights('CartPoleV1.tf')\n",
    "#history = coach.fit(\n",
    "#    [np.array(memory[\"states\"]), np.array(memory[\"masks\"])],\n",
    "#    np.array(memory[\"values\"]),\n",
    "#    epochs=10, batch_size=64, verbose=1)\n",
    "#by = [ agent([b['sp']])          for b in batch ]\n",
    "#print(by)\n",
    "#np.array(by * bm),\n",
    "#by = [ b[\"m\"] * ( b['r'] if b['d'] else b['r'] + a * np.max(agent([b['sp']])[0]) )\n",
    "#           for b in batch ]\n",
    "#print(by, bm)\n",
    "#print(pix)\n",
    "def drawAgent(agent) :\n",
    "    rx = np.arange(-0.24,0.24,0.2, np.float32)\n",
    "    ry = np.arange(-2,2,0.2, np.float32)\n",
    "    def agentDir(x,y) :\n",
    "        [a ,b] = agent([[0.0, 0.0, x, y]])[0]\n",
    "    pix = [\n",
    "        #[ [[type(0.0), type(0.0), type(x), type(y)]] for x in rx]\n",
    "        [ agent([[0.0, 0.0, x, y]])[0] for x in rx]\n",
    "        for y in ry\n",
    "        ]\n",
    "    print(pix)\n",
    "    return\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(15.0, 7.0)         \n",
    "    im = ax.imshow(pix)\n",
    "    ax.set_xticks(np.arange(len(range(-5,15))))\n",
    "    ax.set_yticks(np.arange(len(range(-5,15))))\n",
    "    ax.set_xticklabels(range(-5,15))\n",
    "    ax.set_yticklabels(range(-5,15))\n",
    "    for y in range(len(range(-5,15))):\n",
    "        for x in range(len(range(-5,15))):\n",
    "            text = ax.text(x, y, pix[y][x], ha=\"center\", va=\"center\", color=\"w\")\n",
    "    plt.show()\n",
    "\n",
    "#print(pix)\n",
    "drawAgent(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg = 0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
